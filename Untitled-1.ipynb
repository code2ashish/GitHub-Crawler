{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os \n",
    "import requests\n",
    "import json\n",
    "import openai  \n",
    "from collections import Counter\n",
    "import re\n",
    "import time \n",
    "import git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API credentials\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to fetch user repositories from GitHub\n",
    "github_url='https://github.com/amit986745'\n",
    "    # Extracting username from the GitHub URL\n",
    "username = github_url.split(\"/\")[-1]\n",
    "repos = []\n",
    "\n",
    "#  Create a URL to the GitHub API endpoint\n",
    "url = \"https://api.github.com/users/{}/repos\".format(username)\n",
    "\n",
    "# Make a GET request to the API endpoint\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "\n",
    "    # Get the response data as JSON\n",
    "    data = json.loads(response.content)\n",
    "\n",
    "    # Iterate over the repositories\n",
    "    for repo in data:\n",
    "\n",
    "        # Add the repository name\n",
    "        \n",
    "        repos.append(repo[\"name\"])\n",
    "        \n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Error: HTTP {}.\".format(response.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Adavance-driver-Assistance-systems',\n",
       " 'Football-Analytics',\n",
       " 'NLP-ASSIGNMENT',\n",
       " 'Power-BI',\n",
       " 'Que-Ans-using-bert',\n",
       " 'Question-Similarity-',\n",
       " 'Salary-prediction',\n",
       " 'Sapling',\n",
       " 'travelling-sales-man-problem-using-GA',\n",
       " 'travelling-sales-man-using-genetic-algorithum',\n",
       " 'under_water_research']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(repos))\n",
    "repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        contents = file.read()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_names_from_code(file_path):\n",
    "    if file_path.endswith(\".py\"):\n",
    "        with open(file_path, 'r') as file:\n",
    "            code = file.read()\n",
    "\n",
    "        # Extract library names\n",
    "        library_names = re.findall(r'import\\s+(\\w+)', code)\n",
    "\n",
    "        # Extract function names\n",
    "        function_names = re.findall(r'def\\s+(\\w+)', code)\n",
    "\n",
    "        # Extract class names\n",
    "        class_names = re.findall(r'class\\s+(\\w+)', code)\n",
    "        \n",
    "        # Return the results\n",
    "        return library_names, function_names, class_names\n",
    "        \n",
    "    if file_path.endswith(\".ipynb\"):\n",
    "        # Get the libraries\n",
    "        libraries = re.findall(r\"import\\s+([\\w]+)\", open(file_path).read())\n",
    "\n",
    "        # Get the function names\n",
    "        function_names = re.findall(r\"def\\s+([\\w]+)\\s*\\((.*?)\\)\", open(file_path).read())\n",
    "\n",
    "        # Get the class names\n",
    "        class_names = re.findall(r\"class\\s+([\\w]+)\\s*:\\s*\", open(file_path).read())\n",
    "\n",
    "        # Return the results\n",
    "        return libraries, function_names, class_names\n",
    "\n",
    "\n",
    "def fetch_files_and_folders(folder_path,json={}):\n",
    "\n",
    "    folders = []\n",
    "    library_names=[]\n",
    "    function_names =[]\n",
    "    class_names = []\n",
    "\n",
    "\n",
    "    # Iterate through the contents of the folder\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        \n",
    "        if os.path.isfile(item_path):  # Check if it's a file\n",
    "            try:\n",
    "                file_contents = read_file(item_path)\n",
    "                l,f,c = extract_names_from_code(item_path)\n",
    "\n",
    "                library_names.extend(l)\n",
    "                function_names.extend(f)\n",
    "                class_names.extend(c)\n",
    "            except:\n",
    "                pass\n",
    "        elif os.path.isdir(item_path):  # Check if it's a folder\n",
    "            folders.append(item)\n",
    "\n",
    "    # Iterate through the folders and fetch files recursively\n",
    "\n",
    "    for folder in folders:\n",
    "\n",
    "        for item in os.listdir(os.path.join(folder_path, folder)):\n",
    "            item_path = os.path.join(folder_path, folder, item)\n",
    "\n",
    "            if os.path.isfile(item_path):  # Check if it's a file\n",
    "                try:\n",
    "                    file_contents = read_file(item_path)\n",
    "                    l,f,c = extract_names_from_code(item_path)\n",
    "                    library_names.extend(l)\n",
    "                    function_names.extend(f)\n",
    "                    class_names.extend(c)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "            elif os.path.isdir(item_path):  # Check if it's a folder\n",
    "                pass\n",
    "\n",
    "\n",
    "    return library_names, function_names, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_chatbot(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a user seeking advice on programming language.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature = 0\n",
    "    )\n",
    "\n",
    "    chatbot_response = response.choices[0].message.content\n",
    "    return chatbot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adavance-driver-Assistance-systems\n",
      "clonning..........\n"
     ]
    }
   ],
   "source": [
    "for r in repos:            \n",
    "    print(r)\n",
    "    # clonning of the repos with Github API\n",
    "    repo_url = f\"https://github.com/{username}/{r}.git\"\n",
    "    destination_folder = f\"store/{username}/\"\n",
    "\n",
    "    # Designate a temp folder for clonning of repos of USER\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "        \n",
    "    # Designate a temp folder for clonning of repos inside USER folder\n",
    "    \n",
    "    destination_folder1 = os.path.join(destination_folder,r)\n",
    "    if not os.path.exists(destination_folder1):\n",
    "        os.makedirs(destination_folder1)\n",
    "        print('clonning..........')\n",
    "        git.Repo.clone_from(repo_url, destination_folder1)\n",
    "\n",
    "    # call the function for extracting all the library_names, function_names, class_names\n",
    "\n",
    "    library_names, function_names, class_names = fetch_files_and_folders(destination_folder1,json={})\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"comment about the complexity of the code that have these libraries and functions  and classes\n",
    "            Libraries:\n",
    "            {str(Counter(library_names))[8:-1]}\n",
    "            Functions:\n",
    "            {str(Counter(function_names))[8:-1]}\n",
    "            Classes:\n",
    "            {str(Counter(class_names))[8:-1]}\n",
    "\n",
    "            strictly choose among 'very simple', 'simple', 'moderate', 'high', 'very high'\n",
    "            only no explanation needed and only and only one among these \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment about the complexity of the code that have these libraries and functions  and classes\n",
      "            Libraries:\n",
      "            {'cv2': 4, 'Model': 3, 'load_model': 3, 'cv2_imshow': 3, 'drive': 2, 'os': 2, 'numpy': 2, 'glob': 2, 'matplotlib': 2, 'loadmat': 2, 'tensorflow': 2, 'image': 2, 'load_img': 2, 'img_to_array': 2, 'ImageDataGenerator': 2, 'Input': 2, 'VGG16': 2, 'VGG19': 2, 'Xception': 2, 'ConfigProto': 2, 'InteractiveSession': 2, 'tensorflow_addons': 2, 'xml': 1, 'Conv2D': 1, 'ResNet50': 1}\n",
      "            Functions:\n",
      "            {('conv_block', 'input, num_filters'): 1, ('encoder_block', 'inputs,num_filters'): 1, ('decoder_block', 'input, skip_features, num_filters'): 1, ('build_resnet50_unet', 'input_shape'): 1}\n",
      "            Classes:\n",
      "            \n",
      "\n",
      "            strictly choose among 'very simple', 'simple', 'moderate', 'high', 'very high'\n",
      "            only no explanation needed and only and only one among these \n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the given information, the complexity of the code can be categorized as \"high\".'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_with_chatbot(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''json that has key the repository name and complexity corresponding  to that in values\n",
    "        you need to find the highest complexity repo\n",
    "\n",
    "        {final_complexity}\n",
    "\n",
    "        no need of code and explanation just repo name only'''\n",
    "\n",
    "\n",
    "\n",
    "response = chat_with_chatbot(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
